# Cursor Codebase Search (Index) 全流程技术文档

> **信息来源**：Cursor 官方博客 [Secure Codebase Indexing](https://cursor.com/cn/blog/secure-codebase-indexing)、[Improving Agents with Semantic Search](https://cursor.com/cn/blog/semsearch)、Engineer's Codex [How Cursor Indexes Codebases Fast](https://read.engineerscodex.com/p/how-cursor-indexes-codebases-fast)

---

## 0. 系统架构总览

```
┌─────────────────────────────────────────────────────────────────────┐
│                         Cursor 客户端 (本地)                         │
│                                                                     │
│  ┌──────────┐   ┌─────────────┐   ┌──────────────┐   ┌──────────┐ │
│  │ 文件监听  │──▶│ Merkle 树   │──▶│ 代码分块     │──▶│ 上下文   │ │
│  │ & 扫描    │   │ 构建 & 对比  │   │ (tree-sitter)│   │ 组装     │ │
│  └──────────┘   └──────┬──────┘   └──────┬───────┘   └────┬─────┘ │
│                        │                  │                │       │
│                   哈希树 diff          代码块元数据     代码片段+问题│
│                        │                  │                │       │
└────────────────────────┼──────────────────┼────────────────┼───────┘
                         │                  │                │
                    ─────┼──────── 网络边界 ─┼────────────────┼──────
                         │                  │                │
┌────────────────────────┼──────────────────┼────────────────┼───────┐
│                   Cursor 服务端 (云端)                              │
│                        ▼                  ▼                ▼       │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────────────────┐ │
│  │ Merkle 树    │  │ Embedding    │  │ LLM 推理                 │ │
│  │ 同步 & 存储  │  │ 生成 & 缓存   │  │ (代码理解/补全/对话)      │ │
│  └──────┬───────┘  └──────┬───────┘  └──────────────────────────┘ │
│         │                 │                                        │
│         ▼                 ▼                                        │
│  ┌──────────────┐  ┌──────────────┐                               │
│  │ Simhash      │  │ 向量数据库    │                               │
│  │ 索引复用     │  │ (Turbopuffer) │                               │
│  └──────────────┘  └──────────────┘                               │
│                                                                    │
│  ⚠ 服务端不存储任何源代码原文，仅存储向量 + 加密元数据               │
└────────────────────────────────────────────────────────────────────┘
```

**核心原则**：
- **服务端零代码存储**：云端仅存储向量嵌入 + 加密元数据（文件路径、行号范围），绝不存储源代码原文
- **增量更新**：通过 Merkle 树精确定位变更，仅处理变化的文件和代码块
- **异步处理**：嵌入生成等高成本操作在后台执行，不阻塞用户交互

---

## 1. 文件扫描与 Merkle 树构建

### 1.1 初始扫描

Cursor 打开项目后，首先扫描工作区所有文件：
- 遵守 `.gitignore` 和 `.cursorignore` 的排除规则（如 `node_modules/`、`dist/` 等）
- 为每个需索引的文件计算 **SHA-256 内容哈希**

### 1.2 Merkle 树结构

```
                     Root Hash
                    ╱          ╲
              Dir_A Hash      Dir_B Hash
             ╱    ╲              │
      file1.ts   file2.ts    file3.py
      Hash_1     Hash_2       Hash_3
```

| 节点类型 | 哈希值计算方式 |
|----------|---------------|
| 叶子节点（文件） | `SHA-256(文件内容)` |
| 中间节点（目录） | `SHA-256(子节点哈希的有序拼接)` |
| 根节点 | 代表整个代码库的密码学快照 |

**关键属性**：
- 任何文件的修改，只会改变该文件的哈希值以及**从该文件到根节点的整条路径**上的哈希值
- 对于包含 **50,000 个文件**的工作区，整棵 Merkle 树（文件名 + SHA-256 哈希）仅约 **3.2 MB**
- 每个节点都是其下方内容的加密承诺（cryptographic commitment），拥有文件才能计算出对应哈希

### 1.3 定期同步

Cursor 客户端**每 ~10 分钟扫描一次**项目目录：
1. 重新计算本地 Merkle 树
2. 将本地树与服务器存储的上一版本树进行对比
3. 从根节点开始递归比较：
   - 若某节点哈希相同 → **跳过该整个子树**（无需进一步比较）
   - 若某节点哈希不同 → **递归进入子节点**继续比较
4. 最终精确定位到具体变更的文件列表

```
同步 diff 算法伪代码:

function sync(client_node, server_node):
    if client_node.hash == server_node.hash:
        return  // 子树完全相同，跳过
    
    if is_leaf(client_node):
        upload_for_reindex(client_node.file)  // 文件内容变了，需重新索引
        return
    
    // 目录哈希不同 → 递归比较子节点
    for child in union(client_node.children, server_node.children):
        if child only in client → add_to_index(child)
        if child only in server → remove_from_index(child)
        if child in both → sync(client_child, server_child)
```

**同步保证**：同步过程**绝不修改**客户端本地文件。

---

## 2. 代码分块（Chunking）

### 2.1 为什么需要分块

- 整个文件作为嵌入单元粒度太粗，检索精度低
- 单行代码又太细，缺少语义上下文
- 需要在**语义完整性**和**token 长度限制**之间取得平衡

### 2.2 基于 AST 的语法感知分块

Cursor 在**客户端本地**使用语法分析器（如 **tree-sitter**）进行代码分割：

```
输入文件: src/auth/login.ts (200 行)

tree-sitter 解析 → AST:
├── ImportDeclaration (1-5)
├── InterfaceDeclaration: LoginRequest (7-12)
├── InterfaceDeclaration: LoginResponse (14-20)
├── FunctionDeclaration: validateCredentials (22-45)
├── FunctionDeclaration: generateToken (47-68)
├── ClassDeclaration: AuthService (70-180)
│   ├── MethodDefinition: constructor (72-85)
│   ├── MethodDefinition: login (87-120)
│   ├── MethodDefinition: logout (122-145)
│   └── MethodDefinition: refreshToken (147-178)
└── ExportStatement (180-200)

分块结果:
Chunk 1: imports + interfaces          (行 1-20,  ~150 tokens)
Chunk 2: validateCredentials 函数      (行 22-45, ~200 tokens)
Chunk 3: generateToken 函数            (行 47-68, ~180 tokens)
Chunk 4: AuthService.constructor+login (行 70-120,~400 tokens)
Chunk 5: AuthService.logout+refresh    (行 122-178,~450 tokens)
Chunk 6: export statement              (行 180-200,~50 tokens)
```

**分块策略要点**：
1. **语义边界优先**：按函数、类、方法等 AST 节点进行切割
2. **兄弟节点合并**：如果单个 AST 节点 token 数过少，将相邻兄弟节点合并，以达到合理的 chunk 大小
3. **token 数量控制**：受嵌入模型的 token 限制约束（通常 512-8192 tokens），需要智能平衡片段大小与覆盖范围
4. **元数据附加**：每个 chunk 携带：
   - `file_path`（加密后的文件路径）
   - `start_line` / `end_line`（起止行号）
   - `content`（代码原文，**仅本地保留，不上传**）

### 2.3 分块数据结构

```typescript
interface CodeChunk {
    chunk_id: string;                    // 基于内容的唯一标识（content hash）
    encrypted_file_path: string;         // 加密后的文件路径
    start_line: number;                  // 起始行号
    end_line: number;                    // 结束行号
    content_hash: string;               // 代码内容的 SHA-256 哈希（用于缓存）
    // content: string;                 // ⚠ 代码原文仅在本地，不发送到服务端
}
```

---

## 3. 向量嵌入（Embedding）生成

### 3.1 嵌入生成流程

嵌入生成是**开销最高的步骤**，Cursor 在**后台异步**执行：

```
┌──────────┐     代码块文本      ┌──────────────┐    向量     ┌───────────┐
│ 客户端    │ ──────────────────▶ │ Embedding    │ ─────────▶ │ 向量数据库 │
│ (本地分块) │   (加密传输)        │ 模型 (服务端)  │            │ (Turbopuffer)│
└──────────┘                    └──────────────┘            └───────────┘
```

1. 客户端将代码块文本加密传输到服务端
2. 服务端使用嵌入模型将文本转为高维向量（如 768 维或 1536 维）
3. **仅存储向量 + 加密元数据**，代码原文在生成嵌入后即丢弃

### 3.2 自研嵌入模型

Cursor 训练了**自研嵌入模型**以提升代码检索质量（来源：[Improving Agents with Semantic Search](https://cursor.com/cn/blog/semsearch)）：

**训练数据来源**：
- Agent 会话轨迹（Agent 在多步任务中进行搜索、打开文件、编辑代码的完整操作历史）
- 这些轨迹记录了在真实编码任务中，Agent 实际需要查看和使用的代码片段

**训练方法**：
1. 收集 Agent 会话中的搜索查询和最终使用的代码片段
2. 使用 **LLM 作为 Judge**：让 LLM 对每步操作中哪些检索结果最有帮助进行排序
3. 训练目标：让嵌入模型的相似度评分与 LLM Judge 的排序对齐
4. **核心理念**：从 Agent 实际编码任务中学习，而非仅依赖通用的文本相似度

这使得模型能理解：`"用户查询: 如何处理登录认证"` 应当与 `AuthService.login()` 方法有高相似度，即使两者字面上差异很大。

### 3.3 内容寻址缓存

Cursor 使用**按块内容哈希的缓存策略**：

```
缓存键:  SHA-256(chunk_content)
缓存值:  embedding_vector

查找流程:
1. 计算代码块内容的 SHA-256 哈希
2. 在缓存中查找该哈希
3. 命中 → 直接使用缓存的嵌入向量（跳过模型推理）
4. 未命中 → 调用嵌入模型生成向量，存入缓存
```

**关键优化**：
- 大多数编辑只影响少数代码块，其余块**内容不变 → 哈希不变 → 缓存命中**
- 不同文件中完全相同的代码块也可以复用同一嵌入（内容寻址的天然去重）
- 这使增量更新的嵌入计算成本**与变更量成正比**，而非与代码库总量成正比

---

## 4. 向量存储

### 4.1 存储方案

Cursor 使用 **Turbopuffer** 作为向量数据库：

```
向量数据库中每条记录:
{
    vector: [0.023, -0.156, 0.891, ...],   // 768/1536 维嵌入向量
    metadata: {
        encrypted_path: "enc:a3f2...9b1c",  // 加密后的文件路径
        start_line: 87,                      // 起始行号
        end_line: 120,                       // 结束行号
        workspace_id: "ws_abc123",           // 工作区标识
        chunk_hash: "sha256:e5f6..."         // 块内容哈希
    }
    // ⚠ 注意：没有代码原文字段
}
```

### 4.2 路径加密

文件路径采用**分段加密**策略：

```
原始路径:  src/auth/services/login.ts

分段加密:
  "src"      → encrypt("src",      workspace_key) → "enc:a1b2"
  "auth"     → encrypt("auth",     workspace_key) → "enc:c3d4"
  "services" → encrypt("services", workspace_key) → "enc:e5f6"
  "login.ts" → encrypt("login.ts", workspace_key) → "enc:g7h8"

加密路径:  "enc:a1b2/enc:c3d4/enc:e5f6/enc:g7h8"
```

- 加密密钥**由客户端管理**
- 团队成员可**共享**密钥以共享加密路径
- 即使攻击者获得向量数据库访问权限，也无法识别项目结构或文件名

### 4.3 存储架构选择理由

**为什么选择 Turbopuffer**：
- 原生支持多租户（每个 workspace 独立的命名空间）
- 避免传统数据库分片带来的复杂性
- 高性能向量检索 + 元数据过滤
- 云原生架构，支持弹性扩展

---

## 5. 跨团队索引复用（Index Reuse）

这是 Cursor 将大型仓库首次索引时间从**数小时缩短到秒级**的核心创新。

### 5.1 问题背景

同一组织内，不同开发者 clone 的同一个代码库副本之间相似度平均达 **92%**。为每个新用户从零重建索引是巨大的浪费。

### 5.2 Simhash 相似度检测

**Simhash** 是一种局部敏感哈希（Locality-Sensitive Hash），能将整个代码库的内容压缩为一个固定长度的"指纹"。相似的代码库产生相似的指纹。

```
新用户加入团队的索引复用流程:

1. 客户端构建本地 Merkle 树
2. 从 Merkle 树的叶子节点（所有文件哈希）计算 Simhash 值
                │
                ▼
3. 上传 Simhash 到服务器
                │
                ▼
4. 服务器在团队已有索引的 Simhash 向量库中执行近似检索
                │
                ▼
5. 若相似度 > 阈值 ──── 是 ───▶ 复制该索引作为初始版本
                │                       │
               否                      ▼
                │              6. 后台进行差异同步
                ▼                （增量更新差异部分）
        从零开始全量索引               │
                                      ▼
                              7. 用户可立即发起查询
                                 （基于复制的索引）
```

### 5.3 访问证明（Content Proof）

复用索引面临一个安全问题：**新用户的代码库可能与被复用索引的代码库存在差异**——有些文件新用户可能没有。如果不做过滤，可能泄露新用户未拥有的代码的搜索结果。

**解决方案——利用 Merkle 树的密码学属性**：

```
访问证明流程:

1. 客户端上传完整 Merkle 树 + Simhash
          │
          ▼
2. 服务器将 Merkle 树存储为一组「内容证明」
   （为每个加密路径关联一个文件哈希）
          │
          ▼
3. 搜索时：服务器返回结果前进行过滤
   ┌──────────────────────────────────────────┐
   │ for result in search_results:            │
   │   file_hash = content_proofs[result.path]│
   │   if file_hash 存在于客户端 Merkle 树:    │
   │     ✅ 保留该结果                         │
   │   else:                                  │
   │     ❌ 丢弃该结果（客户端没有该文件）       │
   └──────────────────────────────────────────┘
          │
          ▼
4. 后台差异同步完成后（客户端与服务器 Merkle 树根哈希匹配）:
   → 服务器删除内容证明
   → 后续查询直接在完全同步的索引上运行
```

**为什么安全**：
- Merkle 树中每个节点的哈希是其下方所有内容的密码学承诺
- **只有实际拥有文件的人才能计算出正确的哈希值**
- 伪造某个文件的哈希需要知道该文件的全部内容——而这正是它要保护的

### 5.4 性能提升数据

索引复用带来的首次查询等待时间改善：

| 百分位 | 优化前（全量索引） | 优化后（索引复用） | 加速倍数 |
|--------|-------------------|-------------------|---------|
| **中位数 (P50)** | 7.87 秒 | **525 毫秒** | ~15x |
| **P90** | 2.82 分钟 | **1.87 秒** | ~91x |
| **P99** | 4.03 小时 | **21 秒** | ~691x |

---

## 6. 代码检索流程（运行时）

### 6.1 完整查询链路

```
用户输入: "这个项目中如何处理用户认证？"
                    │
                    ▼
 ┌──────────────────────────────────────────┐
 │  Step 1: 查询向量化（客户端或服务端）       │
 │  query → embedding_model → query_vector   │
 │  [0.045, -0.231, 0.789, ...]             │
 └────────────────┬─────────────────────────┘
                  │
                  ▼
 ┌──────────────────────────────────────────┐
 │  Step 2: 向量数据库检索（服务端）           │
 │  在 Turbopuffer 中执行 ANN 搜索           │
 │  返回 Top-N 最相似的代码块                 │
 │                                           │
 │  结果:                                    │
 │  ┌──────────────────────────────────────┐ │
 │  │ #1 similarity=0.92                   │ │
 │  │    path: "enc:a1/enc:b2/enc:c3"      │ │
 │  │    lines: 87-120                     │ │
 │  │                                      │ │
 │  │ #2 similarity=0.87                   │ │
 │  │    path: "enc:d4/enc:e5/enc:f6"      │ │
 │  │    lines: 22-45                      │ │
 │  │                                      │ │
 │  │ #3 similarity=0.81                   │ │
 │  │    path: "enc:g7/enc:h8/enc:i9"      │ │
 │  │    lines: 1-35                       │ │
 │  └──────────────────────────────────────┘ │
 │  ⚠ 注意：返回的是加密路径+行号，无代码原文  │
 └────────────────┬─────────────────────────┘
                  │
                  ▼
 ┌──────────────────────────────────────────┐
 │  Step 3: 路径解密 & 本地代码提取（客户端）   │
 │                                           │
 │  decrypt("enc:a1/enc:b2/enc:c3")          │
 │  → "src/auth/services/login.ts"           │
 │                                           │
 │  读取本地文件 lines 87-120                 │
 │  → 获得真实代码片段                        │
 └────────────────┬─────────────────────────┘
                  │
                  ▼
 ┌──────────────────────────────────────────┐
 │  Step 4: 上下文组装 & LLM 调用             │
 │                                           │
 │  Prompt:                                  │
 │  ┌──────────────────────────────────────┐ │
 │  │ 以下是项目中的相关代码:               │ │
 │  │                                      │ │
 │  │ --- src/auth/services/login.ts:87-120│ │
 │  │ async login(req: LoginRequest) {     │ │
 │  │   const user = await findUser(...)   │ │
 │  │   ...                                │ │
 │  │ }                                    │ │
 │  │                                      │ │
 │  │ --- src/auth/utils/validate.ts:22-45 │ │
 │  │ function validateCredentials(...) {  │ │
 │  │   ...                                │ │
 │  │ }                                    │ │
 │  │                                      │ │
 │  │ 用户问题: 这个项目中如何处理用户认证？ │ │
 │  └──────────────────────────────────────┘ │
 └────────────────┬─────────────────────────┘
                  │
                  ▼
 ┌──────────────────────────────────────────┐
 │  Step 5: LLM 返回答案                     │
 │  基于检索到的代码上下文生成回答             │
 └──────────────────────────────────────────┘
```

### 6.2 关键安全保证

整个检索过程中的数据流转：

| 阶段 | 数据位置 | 包含源代码？ |
|------|----------|-------------|
| 查询向量化 | 客户端/服务端 | ❌ 只有向量 |
| 向量检索 | 服务端 | ❌ 只有向量+加密元数据 |
| 路径解密 | 客户端 | ❌ 只有解密后的路径 |
| 代码读取 | 客户端本地磁盘 | ✅ 但不上传 |
| LLM 调用 | 服务端 | ✅ 代码片段作为 prompt |

**结论**：向量数据库中**永远不存储源代码**。代码只在最终 LLM 推理时作为 prompt 的一部分出现在服务端。

---

## 7. 增量更新完整流程

将前面各环节串联，一次文件编辑触发的完整更新流程：

```
用户编辑 src/auth/login.ts 并保存
         │
         ▼
[1] 定时扫描检测到变更（~10分钟间隔）
    重新计算 login.ts 的 SHA-256 哈希
    更新 Merkle 树中 login.ts → auth/ → src/ → root 的哈希链
         │
         ▼
[2] 与服务器 Merkle 树对比
    根哈希不同 → src/ 哈希不同 → auth/ 哈希不同 → login.ts 哈希不同
    确定变更文件: login.ts
         │
         ▼
[3] 本地重新分块
    tree-sitter 解析 login.ts 的 AST
    生成新的代码块列表:
    - Chunk A (行 1-20):    内容未变 → hash 相同 → 保留
    - Chunk B (行 22-45):   内容已变 → hash 不同 → 需要重新嵌入
    - Chunk C (行 47-68):   内容未变 → hash 相同 → 保留
    - Chunk D (新增块):      新内容  → 需要生成嵌入
         │
         ▼
[4] 嵌入缓存查找
    Chunk A: cache_key=SHA-256(content_A) → ✅ 命中缓存 → 跳过
    Chunk B: cache_key=SHA-256(content_B') → ❌ 未命中 → 需要嵌入
    Chunk C: cache_key=SHA-256(content_C) → ✅ 命中缓存 → 跳过
    Chunk D: cache_key=SHA-256(content_D) → ❌ 未命中 → 需要嵌入
         │
         ▼
[5] 后台异步生成嵌入（仅 Chunk B 和 Chunk D）
    发送到服务端 embedding 模型
    生成新向量
         │
         ▼
[6] 更新向量数据库
    - 删除旧版 Chunk B 的向量
    - 插入新版 Chunk B 的向量
    - 插入新增 Chunk D 的向量
    - Chunk A、C 保持不变
         │
         ▼
[7] 更新服务端 Merkle 树
    用新的根哈希替换旧版本
```

**效率分析**：假设修改了一个 200 行文件中的 1 个函数（约 30 行），只有包含该函数的 1-2 个 chunk 需要重新嵌入，其余所有 chunk 全部缓存命中。对于 50,000 文件的代码库，这意味着 **99.99%+ 的嵌入计算被跳过**。

---

## 8. 技术栈

根据 Cursor 工程团队公开信息：

| 组件 | 技术选型 | 用途 |
|------|---------|------|
| **客户端语言** | TypeScript + Rust | Rust 处理性能关键型组件（索引、AST 解析） |
| **AST 解析器** | tree-sitter | 多语言语法感知代码分块 |
| **嵌入模型** | 自研模型（基于 Agent 轨迹训练） | 代码块 → 向量转换 |
| **向量数据库** | Turbopuffer | 向量存储与 ANN 检索 |
| **数据流** | Warpstream（Kafka 兼容） | 异步消息传递 |
| **基础设施** | AWS (CPU) + Azure (GPU) | 数万块 NVIDIA H100 用于推理 |
| **IaC** | Terraform | 基础设施即代码 |

---

## 9. 语义搜索效果评估

来自 Cursor 官方 A/B 测试数据（[Improving Agents with Semantic Search](https://cursor.com/cn/blog/semsearch)）：

| 指标 | 效果 |
|------|------|
| **响应准确率提升** | 平均 **12.5%**（范围 6.5%–23.5%） |
| **代码保留率（整体）** | 提升 **0.3%** |
| **代码保留率（大型库 ≥1000 文件）** | 提升 **2.6%** |
| **不满意请求数** | 减少 **2.2%** |

**核心结论**：代码库越大，语义搜索带来的增益越显著——因为大型项目中手动找到相关代码的难度呈指数增长，而向量检索的成本几乎不受规模影响。

---

## 10. 隐私模式与安全设计

### 10.1 标准模式

```
客户端 ──代码块文本──▶ 服务端 ──生成嵌入后丢弃原文──▶ 向量数据库（仅存向量）
```

- 代码文本在嵌入生成后不被持久化
- 文件路径分段加密
- 向量理论上存在可逆性风险（但实际难度极高）

### 10.2 Privacy Mode（隐私模式）

```
客户端 ──本地生成嵌入──▶ 本地向量数据库
                        ↑
                    代码和向量均不离开本地
```

- 嵌入计算在本地完成
- 向量存储在本地
- 完全消除数据泄露风险
- 代价：无法使用跨团队索引复用，首次索引较慢

### 10.3 Git 历史支持

Cursor 还支持对 Git 历史进行索引：
- 记录 commit SHA 和文件变更
- 分支切换时索引自动同步
- 可用于理解代码演变历史

---

## 11. 完整数据流总结

```
┌────────────────────────────────────────────────────────────────────────┐
│                          完整索引生命周期                               │
│                                                                        │
│  [打开项目]                                                            │
│      │                                                                 │
│      ▼                                                                 │
│  文件扫描 ──▶ 构建 Merkle 树 ──▶ 计算 Simhash                         │
│      │              │                   │                              │
│      │              │            ┌──────┴──────┐                       │
│      │              │            │ 服务器检索   │                       │
│      │              │            │ 相似索引     │                       │
│      │              │            └──────┬──────┘                       │
│      │              │                   │                              │
│      │              │         ┌─────────┴─────────┐                    │
│      │              │         │ 相似度 > 阈值？     │                    │
│      │              │         └─────────┬─────────┘                    │
│      │              │              是 ╱   ╲ 否                         │
│      │              │              ╱         ╲                         │
│      │              │     复制已有索引     全量索引构建                   │
│      │              │     + 访问证明过滤   (分块→嵌入→存储)              │
│      │              │              ╲         ╱                         │
│      │              │               ╲     ╱                           │
│      │              │            索引就绪                               │
│      │              │                │                                 │
│      ▼              ▼                ▼                                 │
│  [持续编辑]                                                            │
│      │                                                                 │
│      ▼                                                                 │
│  ~10分钟定时扫描                                                       │
│      │                                                                 │
│      ▼                                                                 │
│  Merkle 树 diff ──▶ 定位变更文件                                       │
│      │                                                                 │
│      ▼                                                                 │
│  重新分块变更文件                                                       │
│      │                                                                 │
│      ▼                                                                 │
│  缓存查找：未变化块跳过，变化块重新嵌入                                   │
│      │                                                                 │
│      ▼                                                                 │
│  更新向量数据库 + 更新 Merkle 树                                        │
│                                                                        │
│  [用户查询]                                                            │
│      │                                                                 │
│      ▼                                                                 │
│  查询向量化 ──▶ 向量检索 ──▶ 返回元数据 ──▶ 本地读码 ──▶ LLM 推理      │
│                                                                        │
└────────────────────────────────────────────────────────────────────────┘
```

---

## 12. 可执行实现要点清单

如果你要实现一个类似的系统，关键决策点：

| # | 决策点 | Cursor 的选择 | 替代方案 |
|---|--------|--------------|---------|
| 1 | AST 解析器 | tree-sitter | LSP、正则、按行分割 |
| 2 | 分块粒度 | 函数/类级别，合并小兄弟节点 | 固定 token 窗口、滑动窗口 |
| 3 | 嵌入模型 | 自研（Agent 轨迹训练） | OpenAI text-embedding-3, Cohere, BGE |
| 4 | 向量数据库 | Turbopuffer（云端多租户） | Pinecone, Qdrant, Weaviate, FAISS(本地) |
| 5 | 变更检测 | Merkle 树 + SHA-256 | 文件修改时间戳, inotify/fswatch |
| 6 | 索引复用 | Simhash + 向量相似检索 | 无（每次全量重建）|
| 7 | 访问控制 | Merkle 树加密证明 | ACL, RBAC |
| 8 | 路径隐私 | 分段加密，客户端管密钥 | 全路径加密, 哈希替代 |
| 9 | 缓存策略 | 内容寻址（content-hash） | LRU, TTL |
| 10 | 同步频率 | ~10 分钟定时 + 事件触发 | 实时 (inotify), 按需 |
